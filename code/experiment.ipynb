{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [Data(x=[i]) for i in range(5)]\n",
    "p=\"./list.pt\"\n",
    "torch.save(l,p)\n",
    "\n",
    "p2 = \"./dict.pt\"\n",
    "d = {\"data_len\":10, 0:\"raw_0.pt\"}\n",
    "torch.save(d, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(p)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_classes import QM9Dataset\n",
    "\n",
    "data = QM9Dataset(root=\"../data/qm9/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b00\n"
     ]
    }
   ],
   "source": [
    "class Example():\n",
    "    \n",
    "    target=\"b00\"\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    \n",
    "    def print():\n",
    "        print(Example.target)\n",
    "        \n",
    "        \n",
    "Example.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[9, 5], edge_index=[2, 72], edge_attr=[72, 5], y=[1, 12], pos=[20, 3], z=[9], name='COCCC#CC1CN1', idx=121542)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get(110000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_data = torch.load(osp.join(\"../data/qm9/processed/\", \"aux_data.pt\"))\n",
    "\n",
    "torch.save(aux_data, osp.join(\"../data/qm9/processed/\", \"aux_data_1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os.path as osp\n",
    "\n",
    "aux_data = torch.load(osp.join(\"../data/qm9/processed/\", \"aux_data.pt\"))\n",
    "\n",
    "step = aux_data[\"step\"]\n",
    "split_factor=50\n",
    "\n",
    "for i in range(split_factor):\n",
    "    curr_end = aux_data[i][\"end\"]\n",
    "    if i == 0:\n",
    "        aux_data[0] = {\"begin\": 0, \"end\": curr_end}\n",
    "    elif i > 0 and i < split_factor -1:\n",
    "        last_end = aux_data[i-1][\"end\"]\n",
    "        aux_data[i] = {\"begin\": last_end, \"end\": last_end + curr_end}\n",
    "    elif i == split_factor-1:\n",
    "        last_end = aux_data[i-1][\"end\"]\n",
    "        # possibly bigger chunk for last dataset\n",
    "        aux_data[i] = {\"begin\": last_end, \"end\": last_end + curr_end}\n",
    "        \n",
    "torch.save(aux_data, osp.join(\"../data/qm9/processed/\", \"aux_data.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "output_dim not given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/harold/epfl/chem-ml-repr/code/experiment.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/harold/epfl/chem-ml-repr/code/experiment.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightning_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LightningClassicGNN\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/harold/epfl/chem-ml-repr/code/experiment.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m LightningClassicGNN\u001b[39m.\u001b[39;49mload_from_checkpoint(\u001b[39m\"\u001b[39;49m\u001b[39m../training_artifacts/test-project/1djimtqv/checkpoints/epoch=0-step=29.ckpt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/chem/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:137\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m     65\u001b[0m ):\n\u001b[1;32m     66\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[39m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_from_checkpoint(\n\u001b[1;32m    138\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m    139\u001b[0m         checkpoint_path,\n\u001b[1;32m    140\u001b[0m         map_location,\n\u001b[1;32m    141\u001b[0m         hparams_file,\n\u001b[1;32m    142\u001b[0m         strict,\n\u001b[1;32m    143\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/chem/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:205\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, pl\u001b[39m.\u001b[39mLightningDataModule):\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_state(\u001b[39mcls\u001b[39m, checkpoint, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m _load_state(\u001b[39mcls\u001b[39;49m, checkpoint, strict\u001b[39m=\u001b[39;49mstrict, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/chem/lib/python3.9/site-packages/pytorch_lightning/core/saving.py:250\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m cls_spec\u001b[39m.\u001b[39mvarkw:\n\u001b[1;32m    247\u001b[0m     \u001b[39m# filter kwargs according to class init unless it allows any argument via kwargs\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     _cls_kwargs \u001b[39m=\u001b[39m {k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m _cls_kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m cls_init_args_name}\n\u001b[0;32m--> 250\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_cls_kwargs)\n\u001b[1;32m    252\u001b[0m \u001b[39m# give model a chance to load something\u001b[39;00m\n\u001b[1;32m    253\u001b[0m obj\u001b[39m.\u001b[39mon_load_checkpoint(checkpoint)\n",
      "File \u001b[0;32m~/epfl/chem-ml-repr/code/lightning_model.py:44\u001b[0m, in \u001b[0;36mLightningClassicGNN.__init__\u001b[0;34m(self, classification, num_hidden_features, dropout_p, learning_rate, num_message_passing_layers, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dim \u001b[39m=\u001b[39m kwargs[\u001b[39m\"\u001b[39m\u001b[39moutput_dim\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39moutput_dim not given\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassification \u001b[39m=\u001b[39m classification        \n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden \u001b[39m=\u001b[39m num_hidden_features\n",
      "\u001b[0;31mValueError\u001b[0m: output_dim not given"
     ]
    }
   ],
   "source": [
    "from lightning_model import LightningClassicGNN\n",
    "\n",
    "LightningClassicGNN.load_from_checkpoint(\"../training_artifacts/test-project/1djimtqv/checkpoints/epoch=0-step=29.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets_classes import QM9Dataset\n",
    "\n",
    "dataset = QM9Dataset(root=\"../data/qm9/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'old_data_len': 1513, 'total_num_skipped': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.load(\"../data/bace/processed/aux_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "class A:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def process(self):\n",
    "        print(\"A\")\n",
    "class B:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def process(self):\n",
    "        print(\"B\")\n",
    "\n",
    "\n",
    "class C(B,A):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "c = C()\n",
    "c.process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('chem')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7714f10ba7f32b0912814c8c283dbc5dfa6a42586c1e0dc83a479c0f665feca8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
